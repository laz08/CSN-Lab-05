---
title: "CSN 05 - Network Dynamics"
author: "Laura Cebollero, Pietro Fronte"
date: "25/11/2018"
output: 
    pdf_document:
        number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("knitr")
options(scipen=999)
```

```{r cache=FALSE, echo=FALSE, include=FALSE}
source("src/00.modelsComparison.R")
```
# Introduction

In this delivery we are asked to simulate three network growth models and study them from a statistical point of view. 

The first one is the original Barabasi Albert model, and the other two are based on this one with some variations:

1. BA: growth & preferential attachment
2. BA': growth & random attachment
3. BA'': No growth & preferential attachment

We are going to discuss the results and the methods used, as well as cover the implementation done and problems encountered.

# Implementation

As asked, we have implemented the simulation on these three models with a fixed $n_{0}$, $m_{0}$ and  $t_{max}$, their values being:

- $n_{0} = 3$
- $m_{0} = 2$
- $t_{max} = 10.000$

This means that for the models with growth (B.A. and B.A.'), on $t = 0$, there will exist 3 nodes fully connected. Meaning we are starting with a fully connected graph. This decision is taken in order to avoid ending up with a disconnected graph, since if we start with a disconnected graph, after the first iteration has been performed, the non-selected node will never be selected and thus we will end up with a disconnected node from the overall graph.

Each time $t$ increases on every iteration, a stub is going to be added. Each stub will consist on a node with $m_{0}$ edges. In our case, $m_{0} = 2$, so each iteration we are going to add two edges to the graph.

This will be performed until reaching $t_{max}$, when the total number of nodes $N$ will be $$N = n_{0} + t_{max} = 3 + 10.000 = 10.003$$

In the third case, B.A.'' (No growth + preferential attachment), we start with 2.000 nodes and end with the same number of nodes. We have chosen a somewhat big number of nodes as suggested in the lab session statement. More specifically, the suggestion was that $N \ge 1000$, and $t_{max}$ has been preserved as in the other two models to preserve coherency. Having a greater $t_{max}$ would have led to a complete graph which is not what we want to achieve.

In those 2 cases where preferential attachment is what determines where each edge from the stub connects to, the higher the number of edges an existing node has, the higher the probability it has to be the one selected for the new addition.

In the first model and second model we do not have to worry on whether we are creating multiedges or not, for each stub is added in every iteration and it cannot select itself. Because of this, we have not used an adjacency matrix and only have tracked the degree evolution of 4 selected nodes, as well as the global degree sequence when reaching $t_{max}$.

However, to avoid having multi-edges on the third model, we have used a sparse adjacency matrix to check whether an edge existed or not before adding it or not. The sparse decision has been taken in order to be more lenient on our computer memories. The usage of such matrix makes the execution of this simulation a little bit slower compared to the other ones.

Below is a table that represents on average the time it has taken us to execute the three simulations:
```{r echo=FALSE}
times = c(5, 3, 35)
names = c("B.A.", "B.A.'", "B.A.''")
times.df = data.frame(names, times)
kable(times.df, caption = "Elapsed times on simulation runs", col.names = c("Simulation", "$\\Delta t (seconds)$ "))
```

As mentioned, we can see how the third simulation (No growth + preferential attachment) is the one which has more cost computationally speaking because of the usage of the adjacency matrix.

# Results
Now we are going to see how is the evolution of 4 vertices until reaching $t_{max}$, as well as what distribution better fits each model.


## Evolution

```{r  cache=T, echo=FALSE, out.width="300px", out.height="300px", fig.align="center"}
plotAllEvolutions(table.BA, "B.A.: Growth + Preferential attachment")
```
In the plot above we can  observe how the first vertex is selected a lot because of the preferential attachment. As the vertex selected chosen is that from a stub added forward in time, clearly its edge degree is going to be lower, thus having a lower preferential attachment for the next iterations. Thus, vertex 100 reaches its highest point at 6 edges, and edge 1000 just 3: the ones created when the node was added as a stub and another iteration where it got selected.

```{r cache=T, echo=FALSE, out.width="300px", out.height="300px", fig.align="center"}
plotAllEvolutions(table.BA.Rand, "B.A.': Growth + Random attachment")
```

Now that the random attachment is done, we can see how the vertices have more or less the same degree distribution. However, since it is a growth model the first vertices (i.e. 1 and 10) still have more chances to be selected on the first iterations, since the number of existing nodes is lower. 

That's why their edge degree reach a higher point than vertices 100 and 1000. 

We can also see how on the last 9000 iterations, vertex 1000 got luckier than vertex 100, for it has one more edge than the other one. Thus, we can see how the randomness plays its hand on the attachment of stubs.

```{r  cache=T, echo=FALSE, out.width="300px", out.height="300px", fig.align="center"}
plotAllEvolutions(table.BA.no.growth, "B.A.'': No Growth + Preferential attachment")
```
In this case we can see how the no-growth and preferential attachment have their effects on the simulation model.

On the first iteration all vertices (2000) have the same chance to get selected. Afterwards, those that got lucky and got selected on the first iterations have a higher probability to get selected again.

In this case, it seems that vertex 1000 got lucky and got selected a lot more than its 3 other counterparts.


## Scaling of vertex degree over time

Now let's take a look on how these vertices' evolution grow comparing them with the theoretical $k_{i}$. Each simulation has its own theoretical average growth.

### Growth and preferential attachment

On the first simulation model, the formula to follow is $$k_{i}''(t) = m_{0}^{t_{0}} = m_{0} \sqrt{t_{0}}$$

This theoretical evolution has been painted in pink in the plot below.


```{r echo=FALSE, out.width="300px", out.height="300px", fig.align="center"}
plot_ki(table.BA, "topleft", "gp") # growth preferential
```

We can see how vertex 1 follows somewhat closely that theoretical evolution. Of course, the vertices added later in time do not follow this evolution, for they have a lower chance to get chosen on the preferential attachment.


```{r echo=FALSE}
kable(suppressWarnings(do.call(rbind, apply(table.BA[,-1],2, model_selection_vertex_growth))))
```

In this table....
TODO: Piero, can you comment on this?


### Growth and random attachment

Now the scalingof vertex degree over time is as follows:
$$k_{i}''(t) = m_{0} log(m_{0} + t - 1)$$

We can see how the first vertex follows it closely and the other 3 also tend to stagnate (later, of course, since they are added later on).

```{r echo=FALSE, out.width="300px", out.height="300px", fig.align="center"}
plot_ki(table.BA.Rand, "bottomright", "gr") # growth random
```

```{r echo=FALSE}
kable(suppressWarnings(do.call(rbind, apply(table.BA.Rand[,-1],2, model_selection_vertex_growth))))
```
TODO: Piero, can you comment on this?


### No Growth and preferential attachment

Now $$k_{i}(t) =  \frac{2 m_{0}}{n_{0}} t$$ for every vertex.

We can see how, more or less, they all follow this vertex degree scaling. They vary a little because of the preferential attachment.

```{r echo=FALSE, out.width="300px", out.height="300px", fig.align="center"}
plot_ki(table.BA.no.growth, "bottomright", "ngp") # no growth preferential
```

```{r echo=FALSE}
kable(suppressWarnings(do.call(rbind, apply(table.BA.no.growth[,-1],2, model_selection_vertex_growth))))
```

TODO: Piero, can you comment on this??


## Degree distribution

Now let's check which degree distribution fits better each simulation model.

To select the best distribution fitting our final degree sequence of each model, we are going to use the functions used on lab. session 2.

Afterwards, we are going to select the model that has the lowest AIC value.

### Growth and preferential attachment

In this case, the model selected that has the lowest AIC, thus the model that best fits the final degree sequence is:

```{r echo=FALSE}
cat("Best fitting for B.A. Growth + preferential:", as.character(df1[minAIC.1,]$Model), " with parameter value", df1[minAIC.1,"Param1"] , "\n")
```

Let's see how this fits our degree distribution:
```{r echo=FALSE, out.width="300px", out.height="300px", fig.align="center"}
 t = table(final.BA.seq)
    prob = t/sum(t)
    plot(as.vector(prob), main = "Growth + Preferential attachment", ylab = "Probability", xlab = "x", col="black", cex=0.55)
    lines(as.vector(prob), col = "blue", lwd = 3.5)
    lines(dgeom(0:max(final.BA.seq), prob =  geom_param1), col = "red", lwd = 2)
    grid()
    box()
    legend("topright", legend = c("Geometric", "Simulation degree sequence"), pch = 19, col=c("red", "blue"))
```

### Growth and random attachment

On the second model, the best fitting distribution is:
```{r echo=FALSE}
cat("Best fitting for B.A. Growth + random attachment:", as.character(df2[minAIC.2,]$Model), " with parameter value", df2[minAIC.2,"Param1"] , "\n")
```

```{r echo=FALSE, out.width="300px", out.height="300px", fig.align="center"}
 t = table(final.BA.Rand.Att.seq)
    prob = t/sum(t)
    plot(as.vector(prob), main = "Growth + Random attachment", ylab = "Probability", xlab = "x", col="black", cex=0.55)
    lines(as.vector(prob), col = "blue", lwd = 3.5)
    lines(dpois(0:max(final.BA.seq), lambda =  poisson_param), col = "red", lwd = 2)
    grid()
    box()
    legend("topright", legend = c("Poisson", "Simulation degree sequence"), pch = 19, col=c("red", "blue"))
```

### No Growth and preferential attachment

Finally, on the third model, the best fitting distribution is:
```{r echo=FALSE}
cat("Best fitting for B.A. Growth + random attachment:", as.character(df3[minAIC.3,]$Model), " with parameter value", df3[minAIC.3,"Param1"] , "\n")
```

```{r echo=FALSE, out.width="300px", out.height="300px", fig.align="center"}
t = table(final.BA.Rand.Att.seq)
    prob = t/sum(t)
    plot(as.vector(prob), main = "NO growth + Preferential Attachment", ylab = "Probability", xlab = "x", col = "grey")
    lines(as.vector(prob), col = "blue", lwd = 3.5)
    lines(dgeom(0:max(final.BA.Rand.Att.seq), prob =  geom_param2), col = "red", lwd = 2)
    legend("topright", legend = c("Geometric", "Simulation degree sequence"), pch = 19, col=c("red", "blue"))
    box()
    grid()
```

TODO: This does not make sense


# Conclusions

We can see how x model fits ...

Some possible future work would be to see whether the best fitting distributions change when $$n_{0} \ge 3$$ and $$m_{0} \ge 2$$

Since we have not had enough time to perform these tests, we have made these two parameters static. It would be interesting to see the effects on changing them.